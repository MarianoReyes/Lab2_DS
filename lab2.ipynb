{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 2 Data Science\n",
    "- Kenneth Gálvez 20079\n",
    "- José Mariano Reyes 20074"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Cargar los datos desde los archivos .p\n",
    "with open('entrenamiento.p', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "    \n",
    "with open('validacion.p', 'rb') as f:\n",
    "    validation_data = pickle.load(f)\n",
    "    \n",
    "with open('prueba.p', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "# Dividir los datos en imágenes y etiquetas\n",
    "x_train, y_train = train_data['features'], train_data['labels']\n",
    "x_val, y_val = validation_data['features'], validation_data['labels']\n",
    "x_test, y_test = test_data['features'], test_data['labels']\n",
    "\n",
    "# Preprocesamiento: Redimensionar y Normalizar\n",
    "input_shape = (32, 32, 3)  # Por ejemplo, redimensionar a 32x32 y 3 canales de color (RGB)\n",
    "x_train = x_train / 255.0  # Normalización\n",
    "x_val = x_val / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Preprocesamiento: Codificación One-Hot para las etiquetas\n",
    "num_classes = 43\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_val = to_categorical(y_val, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementación de la arquitectura Le-Net\n",
    "\n",
    "### Arquitectura LeNet:\n",
    "\n",
    "La arquitectura LeNet fue propuesta por Yann LeCun en 1998 y es considerada una de las primeras arquitecturas exitosas de redes neuronales convolucionales. Fue diseñada para el reconocimiento de caracteres escritos a mano y, aunque es relativamente simple en comparación con las CNN modernas, sienta las bases para muchas de las arquitecturas posteriores. La arquitectura LeNet consta de las siguientes capas:\n",
    "\n",
    "1. Capa de Convolución (C1): Convolución 2D con filtros (kernels) de tamaño pequeño. Aplicación de función de activación, típicamente ReLU (Rectified Linear Unit).Captura características locales en la imagen, como bordes y texturas.\n",
    "\n",
    "2. Capa de Sub-muestreo (Pooling) (S2): Operación de sub-muestreo, como MaxPooling, para reducir el tamaño de la imagen. Ayuda a conservar las características más importantes y reduce la cantidad de parámetros.\n",
    "\n",
    "3. Capa de Convolución (C3): Otra capa de convolución con filtros más grandes. Función de activación ReLU. Captura características más abstractas basadas en las características capturadas en C1.\n",
    "\n",
    "4. Capa de Sub-muestreo (Pooling) (S4): Otra operación de sub-muestreo para reducir el tamaño aún más.\n",
    "\n",
    "5. Capa completamente conectada (Fully Connected) (F5): Capa densamente conectada con unidades de activación ReLU. Captura relaciones más complejas entre las características capturadas en capas anteriores.\n",
    "\n",
    "6. Capa completamente conectada (Fully Connected) (F6): Capa final que produce las salidas finales de clasificación. Puede tener unidades de activación lineales o softmax, dependiendo del problema.\n",
    "\n",
    "### Diagrama de la Red LeNet (png entregado aparte)\n",
    "\n",
    "### Proceso de Convolución, Función de Activación y Pooling:\n",
    "\n",
    "1. Convolución: En la capa de convolución, los filtros se deslizan sobre la imagen de entrada realizando productos escalares locales. Esto ayuda a detectar patrones específicos como bordes, texturas y características relevantes en la imagen.\n",
    "\n",
    "2. Función de Activación: Después de cada operación de convolución, se aplica una función de activación, como la función ReLU. ReLU convierte los valores negativos en cero y mantiene los valores positivos sin cambios. Esto introduce no linealidades en la red, lo que le permite capturar relaciones más complejas.\n",
    "\n",
    "3. Pooling (Sub-muestreo): La operación de pooling reduce el tamaño espacial de la representación de la imagen mientras mantiene las características más importantes. MaxPooling, por ejemplo, selecciona el valor máximo dentro de una ventana en la imagen. Esto ayuda a reducir la cantidad de parámetros y hacer que la red sea más robusta a pequeñas transformaciones en la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Construcción del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Definición del modelo LeNet\n",
    "model = models.Sequential()\n",
    "\n",
    "# Capa de Convolución (C1)\n",
    "model.add(layers.Conv2D(filters=6, kernel_size=(5, 5), activation='relu', input_shape=(32, 32, 3)))\n",
    "# Capa de Sub-muestreo (S2)\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Capa de Convolución (C3)\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(5, 5), activation='relu'))\n",
    "# Capa de Sub-muestreo (S4)\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Aplanar los datos para las capas Fully Connected\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Capa Fully Connected (F5)\n",
    "model.add(layers.Dense(units=120, activation='relu'))\n",
    "\n",
    "# Capa Fully Connected (F6)\n",
    "model.add(layers.Dense(units=84, activation='relu'))\n",
    "\n",
    "# Capa de Salida\n",
    "model.add(layers.Dense(units=43, activation='softmax'))  # 43 clases en este caso\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "544/544 [==============================] - 8s 13ms/step - loss: 1.4440 - accuracy: 0.6232 - val_loss: 0.7442 - val_accuracy: 0.8145\n",
      "Epoch 2/10\n",
      "544/544 [==============================] - 6s 11ms/step - loss: 0.3671 - accuracy: 0.9025 - val_loss: 0.5995 - val_accuracy: 0.8388\n",
      "Epoch 3/10\n",
      "544/544 [==============================] - 6s 11ms/step - loss: 0.2108 - accuracy: 0.9447 - val_loss: 0.5406 - val_accuracy: 0.8503\n",
      "Epoch 4/10\n",
      "544/544 [==============================] - 6s 11ms/step - loss: 0.1448 - accuracy: 0.9633 - val_loss: 0.4810 - val_accuracy: 0.8828\n",
      "Epoch 5/10\n",
      "544/544 [==============================] - 6s 11ms/step - loss: 0.1065 - accuracy: 0.9717 - val_loss: 0.3554 - val_accuracy: 0.9132\n",
      "Epoch 6/10\n",
      "544/544 [==============================] - 6s 11ms/step - loss: 0.0838 - accuracy: 0.9779 - val_loss: 0.4039 - val_accuracy: 0.9116\n",
      "Epoch 7/10\n",
      "544/544 [==============================] - 6s 11ms/step - loss: 0.0689 - accuracy: 0.9823 - val_loss: 0.3894 - val_accuracy: 0.9134\n",
      "Epoch 8/10\n",
      "544/544 [==============================] - 6s 11ms/step - loss: 0.0532 - accuracy: 0.9860 - val_loss: 0.5545 - val_accuracy: 0.8914\n",
      "Epoch 9/10\n",
      "544/544 [==============================] - 6s 11ms/step - loss: 0.0441 - accuracy: 0.9880 - val_loss: 0.4387 - val_accuracy: 0.9229\n",
      "Epoch 10/10\n",
      "544/544 [==============================] - 6s 11ms/step - loss: 0.0412 - accuracy: 0.9878 - val_loss: 0.4362 - val_accuracy: 0.9181\n"
     ]
    }
   ],
   "source": [
    "# Definir hiperparámetros\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                    validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 2s 4ms/step\n",
      "Precisión en el conjunto de prueba: 0.9079968329374505\n",
      "F1-Score en el conjunto de prueba: 0.9074452517726638\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Etiquetas reales en el conjunto de prueba\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "\n",
    "print(f\"Precisión en el conjunto de prueba: {accuracy}\")\n",
    "print(f\"F1-Score en el conjunto de prueba: {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretación de Resultados\n",
    "\n",
    "El modelo muestra un desempeño bueno en los conjuntos de entrenamiento y validación, con una precisión cercana al 98% después de 10 épocas. Pero en el conjunto de prueba, la precisión es fue un poco más baja, alrededor del 90.8%. Creemos que este desajuste se debe a un sobreajuste en los datos de entrenamiento. Igual consideramos que este resultado es bastante impresionante, considerando la complejidad y la variabilidad de las señales de tráfico en las 43 clases.\n",
    "\n",
    "El F1-Score también fue es alto, lo que significa que el modelo tiene un buen equilibrio entre la precisión y la capacidad para recuperar las instancias relevantes de cada clase. Al analizar el desempeño por clase, observamos que algunas clases tienen una precisión y un F1-Score notablemente altos, mientras que otras pueden tener un rendimiento menor. Esto podría deberse a desafíos específicos de cada clase, como el tamaño de la muestra o la complejidad de las señales. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Mejoras y Experimentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos Realizados:\n",
    "En un esfuerzo por mejorar el rendimiento del modelo, se realizó un experimento utilizando aumento de datos. Se aplicó una técnica de aumento de datos que incluye rotación, desplazamiento y reflejo horizontal a las imágenes del conjunto de entrenamiento. El objetivo era aumentar la variabilidad de los datos y hacer que el modelo sea más resistente a las variaciones en las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "543/543 [==============================] - 13s 23ms/step - loss: 2.4339 - accuracy: 0.3149 - val_loss: 1.6841 - val_accuracy: 0.4558\n",
      "Epoch 2/20\n",
      "543/543 [==============================] - 13s 23ms/step - loss: 1.3879 - accuracy: 0.5552 - val_loss: 1.3539 - val_accuracy: 0.5664\n",
      "Epoch 3/20\n",
      "543/543 [==============================] - 14s 27ms/step - loss: 1.0485 - accuracy: 0.6575 - val_loss: 1.2008 - val_accuracy: 0.6188\n",
      "Epoch 4/20\n",
      "543/543 [==============================] - 14s 26ms/step - loss: 0.8509 - accuracy: 0.7207 - val_loss: 1.0730 - val_accuracy: 0.6553\n",
      "Epoch 5/20\n",
      "543/543 [==============================] - 13s 24ms/step - loss: 0.7045 - accuracy: 0.7669 - val_loss: 1.0479 - val_accuracy: 0.6744\n",
      "Epoch 6/20\n",
      "543/543 [==============================] - 13s 23ms/step - loss: 0.6177 - accuracy: 0.7968 - val_loss: 0.9479 - val_accuracy: 0.7358\n",
      "Epoch 7/20\n",
      "543/543 [==============================] - 12s 23ms/step - loss: 0.5350 - accuracy: 0.8235 - val_loss: 0.9131 - val_accuracy: 0.7354\n",
      "Epoch 8/20\n",
      "543/543 [==============================] - 13s 23ms/step - loss: 0.4843 - accuracy: 0.8397 - val_loss: 0.9762 - val_accuracy: 0.7270\n",
      "Epoch 9/20\n",
      "543/543 [==============================] - 13s 23ms/step - loss: 0.4488 - accuracy: 0.8541 - val_loss: 0.8957 - val_accuracy: 0.7601\n",
      "Epoch 10/20\n",
      "543/543 [==============================] - 13s 23ms/step - loss: 0.3997 - accuracy: 0.8702 - val_loss: 0.9646 - val_accuracy: 0.7481\n",
      "Epoch 11/20\n",
      "543/543 [==============================] - 13s 25ms/step - loss: 0.3932 - accuracy: 0.8698 - val_loss: 0.9842 - val_accuracy: 0.7610\n",
      "Epoch 12/20\n",
      "543/543 [==============================] - 13s 23ms/step - loss: 0.3584 - accuracy: 0.8821 - val_loss: 0.9188 - val_accuracy: 0.7807\n",
      "Epoch 13/20\n",
      "543/543 [==============================] - 13s 23ms/step - loss: 0.3448 - accuracy: 0.8856 - val_loss: 0.9724 - val_accuracy: 0.7751\n",
      "Epoch 14/20\n",
      "543/543 [==============================] - 12s 23ms/step - loss: 0.3148 - accuracy: 0.8970 - val_loss: 0.9717 - val_accuracy: 0.7730\n",
      "Epoch 15/20\n",
      "543/543 [==============================] - 12s 23ms/step - loss: 0.3061 - accuracy: 0.8989 - val_loss: 0.9165 - val_accuracy: 0.7751\n",
      "Epoch 16/20\n",
      "543/543 [==============================] - 13s 24ms/step - loss: 0.2956 - accuracy: 0.9020 - val_loss: 0.9425 - val_accuracy: 0.7705\n",
      "Epoch 17/20\n",
      "543/543 [==============================] - 13s 23ms/step - loss: 0.2777 - accuracy: 0.9088 - val_loss: 0.9781 - val_accuracy: 0.7966\n",
      "Epoch 18/20\n",
      "543/543 [==============================] - 13s 23ms/step - loss: 0.2697 - accuracy: 0.9112 - val_loss: 0.9223 - val_accuracy: 0.7912\n",
      "Epoch 19/20\n",
      "543/543 [==============================] - 13s 23ms/step - loss: 0.2579 - accuracy: 0.9158 - val_loss: 1.0008 - val_accuracy: 0.7791\n",
      "Epoch 20/20\n",
      "543/543 [==============================] - 13s 23ms/step - loss: 0.2538 - accuracy: 0.9187 - val_loss: 0.9766 - val_accuracy: 0.7991\n",
      "395/395 [==============================] - 1s 3ms/step\n",
      "Precisión en el conjunto de prueba: 0.8364212193190815\n",
      "F1-Score en el conjunto de prueba: 0.8344731554348864\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Cargar los datos desde los archivos .p\n",
    "with open('entrenamiento.p', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "    \n",
    "with open('validacion.p', 'rb') as f:\n",
    "    validation_data = pickle.load(f)\n",
    "    \n",
    "with open('prueba.p', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "# Dividir los datos en imágenes y etiquetas\n",
    "x_train, y_train = train_data['features'], train_data['labels']\n",
    "x_val, y_val = validation_data['features'], validation_data['labels']\n",
    "x_test, y_test = test_data['features'], test_data['labels']\n",
    "\n",
    "# Preprocesamiento: Redimensionar y Normalizar\n",
    "input_shape = (32, 32, 3)\n",
    "x_train = x_train / 255.0\n",
    "x_val = x_val / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Codificación One-Hot para las etiquetas\n",
    "num_classes = 43\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_val = to_categorical(y_val, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Experimento: Aumento de Datos\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,  # Rotación máxima de 10 grados\n",
    "    width_shift_range=0.1,  # Desplazamiento horizontal máximo del 10% del ancho\n",
    "    height_shift_range=0.1,  # Desplazamiento vertical máximo del 10% de la altura\n",
    "    horizontal_flip=True  # Reflejo horizontal aleatorio\n",
    ")\n",
    "\n",
    "# Crear un generador de datos para el conjunto de entrenamiento\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Definir hiperparámetros para el entrenamiento con aumento de datos\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "\n",
    "# Definir el modelo LeNet con Keras\n",
    "\n",
    "# Definición del modelo LeNet\n",
    "model = models.Sequential()\n",
    "\n",
    "# Capa de Convolución (C1)\n",
    "model.add(layers.Conv2D(filters=6, kernel_size=(5, 5), activation='relu', input_shape=(32, 32, 3)))\n",
    "# Capa de Sub-muestreo (S2)\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Capa de Convolución (C3)\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(5, 5), activation='relu'))\n",
    "# Capa de Sub-muestreo (S4)\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Aplanar los datos para las capas Fully Connected\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Capa Fully Connected (F5)\n",
    "model.add(layers.Dense(units=120, activation='relu'))\n",
    "\n",
    "# Capa Fully Connected (F6)\n",
    "model.add(layers.Dense(units=84, activation='relu'))\n",
    "\n",
    "# Capa de Salida\n",
    "model.add(layers.Dense(units=43, activation='softmax'))  # 43 clases en este caso\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento del modelo con aumento de datos\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(x_train) // batch_size,\n",
    "                    epochs=epochs, validation_data=(x_val, y_val))\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "\n",
    "print(f\"Precisión en el conjunto de prueba: {accuracy}\")\n",
    "print(f\"F1-Score en el conjunto de prueba: {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflexión sobre Resultados:\n",
    "Los resultados del experimento que involucró la técnica de aumento de datos muestran un desempeño ligeramente diferente en comparación con el modelo anterior. A pesar de que se obtuvo una precisión en el conjunto de prueba de alrededor del 83.6% y un F1-Score de aproximadamente 83.4%, estos valores son más bajos que los obtenidos en el modelo original sin modificaciones drásticas.\n",
    "\n",
    "Concluimos que en este caso particular, la aplicación de técnicas de aumento de datos no necesariamente mejoró el rendimiento del modelo de manera positiva, Aunque la idea detrás del aumento de datos es incrementar la variabilidad de los datos de entrenamiento y mejorar la capacidad de generalización del modelo era buena, pues es importante recordar que no todas las técnicas funcionarán igualmente bien para todos los conjuntos de datos.\n",
    "\n",
    "Es posible que las señales de tráfico tengan características intrínsecas que no se beneficiaron significativamente del aumento de datos en este experimento. Los desafíos específicos de algunas clases pueden requerir enfoques más específicos para mejorar su rendimiento. \n",
    "\n",
    "La leccion mas importantes que nos llevamos de este laboratorio es que en situaciones del mundo real, estos resultados nos recuerdan la importancia de explorar diversas estrategias y ajustarlas según las características particulares del conjunto de datos. La adaptación y el ajuste cuidadoso de las técnicas de mejora del rendimiento son esenciales para lograr un modelo de clasificación efectivo y robusto en diferentes situaciones prácticas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
