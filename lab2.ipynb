{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 2 Data Science\n",
    "- Kenneth Gálvez 20079\n",
    "- José Mariano Reyes 20074"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Cargar los datos desde los archivos .p\n",
    "with open('entrenamiento.p', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "    \n",
    "with open('validacion.p', 'rb') as f:\n",
    "    validation_data = pickle.load(f)\n",
    "    \n",
    "with open('prueba.p', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "# Dividir los datos en imágenes y etiquetas\n",
    "x_train, y_train = train_data['features'], train_data['labels']\n",
    "x_val, y_val = validation_data['features'], validation_data['labels']\n",
    "x_test, y_test = test_data['features'], test_data['labels']\n",
    "\n",
    "# Preprocesamiento: Redimensionar y Normalizar\n",
    "input_shape = (32, 32, 3)  # Por ejemplo, redimensionar a 32x32 y 3 canales de color (RGB)\n",
    "x_train = x_train / 255.0  # Normalización\n",
    "x_val = x_val / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Preprocesamiento: Codificación One-Hot para las etiquetas\n",
    "num_classes = 43\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_val = to_categorical(y_val, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementación de la arquitectura Le-Net\n",
    "\n",
    "### Arquitectura LeNet:\n",
    "\n",
    "La arquitectura LeNet fue propuesta por Yann LeCun en 1998 y es considerada una de las primeras arquitecturas exitosas de redes neuronales convolucionales. Fue diseñada para el reconocimiento de caracteres escritos a mano y, aunque es relativamente simple en comparación con las CNN modernas, sienta las bases para muchas de las arquitecturas posteriores. La arquitectura LeNet consta de las siguientes capas:\n",
    "\n",
    "1. Capa de Convolución (C1): Convolución 2D con filtros (kernels) de tamaño pequeño. Aplicación de función de activación, típicamente ReLU (Rectified Linear Unit).Captura características locales en la imagen, como bordes y texturas.\n",
    "\n",
    "2. Capa de Sub-muestreo (Pooling) (S2): Operación de sub-muestreo, como MaxPooling, para reducir el tamaño de la imagen. Ayuda a conservar las características más importantes y reduce la cantidad de parámetros.\n",
    "\n",
    "3. Capa de Convolución (C3): Otra capa de convolución con filtros más grandes. Función de activación ReLU. Captura características más abstractas basadas en las características capturadas en C1.\n",
    "\n",
    "4. Capa de Sub-muestreo (Pooling) (S4): Otra operación de sub-muestreo para reducir el tamaño aún más.\n",
    "\n",
    "5. Capa completamente conectada (Fully Connected) (F5): Capa densamente conectada con unidades de activación ReLU. Captura relaciones más complejas entre las características capturadas en capas anteriores.\n",
    "\n",
    "6. Capa completamente conectada (Fully Connected) (F6): Capa final que produce las salidas finales de clasificación. Puede tener unidades de activación lineales o softmax, dependiendo del problema.\n",
    "\n",
    "### Diagrama de la Red LeNet (png entregado aparte)\n",
    "\n",
    "### Proceso de Convolución, Función de Activación y Pooling:\n",
    "\n",
    "1. Convolución: En la capa de convolución, los filtros se deslizan sobre la imagen de entrada realizando productos escalares locales. Esto ayuda a detectar patrones específicos como bordes, texturas y características relevantes en la imagen.\n",
    "\n",
    "2. Función de Activación: Después de cada operación de convolución, se aplica una función de activación, como la función ReLU. ReLU convierte los valores negativos en cero y mantiene los valores positivos sin cambios. Esto introduce no linealidades en la red, lo que le permite capturar relaciones más complejas.\n",
    "\n",
    "3. Pooling (Sub-muestreo): La operación de pooling reduce el tamaño espacial de la representación de la imagen mientras mantiene las características más importantes. MaxPooling, por ejemplo, selecciona el valor máximo dentro de una ventana en la imagen. Esto ayuda a reducir la cantidad de parámetros y hacer que la red sea más robusta a pequeñas transformaciones en la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Construcción del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Definición del modelo LeNet\n",
    "model = models.Sequential()\n",
    "\n",
    "# Capa de Convolución (C1)\n",
    "model.add(layers.Conv2D(filters=6, kernel_size=(5, 5), activation='relu', input_shape=(32, 32, 3)))\n",
    "# Capa de Sub-muestreo (S2)\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Capa de Convolución (C3)\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(5, 5), activation='relu'))\n",
    "# Capa de Sub-muestreo (S4)\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Aplanar los datos para las capas Fully Connected\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Capa Fully Connected (F5)\n",
    "model.add(layers.Dense(units=120, activation='relu'))\n",
    "\n",
    "# Capa Fully Connected (F6)\n",
    "model.add(layers.Dense(units=84, activation='relu'))\n",
    "\n",
    "# Capa de Salida\n",
    "model.add(layers.Dense(units=43, activation='softmax'))  # 43 clases en este caso\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
